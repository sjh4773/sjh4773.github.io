<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Blending 기법 - My New Hugo Site</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Blending 기법" />
<meta property="og:description" content="예측값을 변수로 활용하는 앙상블 테크닉 Blending Blending 은 Ensemble 의 한 종류입니다. Ensemble 이란 예측 모형을 통합해서 하나의 예측을 수행하는 것을 말합니다. Ensemble 의 묘미는 서로 다른 예측 모형들을 합쳐 더 강한 예측 모형을 만들 수 있다는 것입니다. 가령 정확도 0.7, 0.7 인 모델 두 개를 합쳐서 0.9 을 만들 수 있습니다.
Blending 의 프로세스 1. Traning/Validation/Test set 을 나눈다. 2. Training set 에 모델 피팅을 한다. 3. Validation/Test set 에 대해 예측을 한다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://sjh4773.github.io/post/machine-learning-12/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2021-04-28T23:39:00&#43;00:00" />
<meta property="article:modified_time" content="2021-04-28T23:39:00&#43;00:00" />


		<meta itemprop="name" content="Blending 기법">
<meta itemprop="description" content="예측값을 변수로 활용하는 앙상블 테크닉 Blending Blending 은 Ensemble 의 한 종류입니다. Ensemble 이란 예측 모형을 통합해서 하나의 예측을 수행하는 것을 말합니다. Ensemble 의 묘미는 서로 다른 예측 모형들을 합쳐 더 강한 예측 모형을 만들 수 있다는 것입니다. 가령 정확도 0.7, 0.7 인 모델 두 개를 합쳐서 0.9 을 만들 수 있습니다.
Blending 의 프로세스 1. Traning/Validation/Test set 을 나눈다. 2. Training set 에 모델 피팅을 한다. 3. Validation/Test set 에 대해 예측을 한다."><meta itemprop="datePublished" content="2021-04-28T23:39:00&#43;00:00" />
<meta itemprop="dateModified" content="2021-04-28T23:39:00&#43;00:00" />
<meta itemprop="wordCount" content="392">
<meta itemprop="keywords" content="machine_learning," />
		<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Blending 기법"/>
<meta name="twitter:description" content="예측값을 변수로 활용하는 앙상블 테크닉 Blending Blending 은 Ensemble 의 한 종류입니다. Ensemble 이란 예측 모형을 통합해서 하나의 예측을 수행하는 것을 말합니다. Ensemble 의 묘미는 서로 다른 예측 모형들을 합쳐 더 강한 예측 모형을 만들 수 있다는 것입니다. 가령 정확도 0.7, 0.7 인 모델 두 개를 합쳐서 0.9 을 만들 수 있습니다.
Blending 의 프로세스 1. Traning/Validation/Test set 을 나눈다. 2. Training set 에 모델 피팅을 한다. 3. Validation/Test set 에 대해 예측을 한다."/>

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	<link rel="stylesheet" href="/css/custom.css">

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="My New Hugo Site" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">My New Hugo Site</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Blending 기법</h1>
			<div class="post__meta meta"><div class="meta__item-author meta__item">
	<svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2 0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class="meta__text">JiHun</span>
</div>
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2021-04-28T23:39:00Z">2021-04-28</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/machine_learning/" rel="category">machine_learning</a>
	</span>
</div></div>
		</header>
<div class="post__toc toc">
	<div class="toc__title">Page content</div>
	<div class="toc__menu">
		<nav id="TableOfContents">
  <ul>
    <li><a href="#blending-의-프로세스">Blending 의 프로세스</a></li>
    <li><a href="#blending-과-stacking-의-차이점">Blending 과 Stacking 의 차이점</a></li>
  </ul>
</nav>
	</div>
</div><div class="content post__content clearfix">
			<h1 id="예측값을-변수로-활용하는-앙상블-테크닉-blending">예측값을 변수로 활용하는 앙상블 테크닉 Blending</h1>
<p>Blending 은 Ensemble 의 한 종류입니다. Ensemble 이란 예측 모형을 통합해서 하나의 예측을 수행하는 것을 말합니다.
Ensemble 의 묘미는 서로 다른 예측 모형들을 합쳐 더 강한 예측 모형을 만들 수 있다는 것입니다. 가령 정확도 0.7, 0.7 인 모델 두 개를 합쳐서 0.9 을 만들 수 있습니다.</p>
<p><img src="/image/blending.PNG" alt=""></p>
<h2 id="blending-의-프로세스">Blending 의 프로세스</h2>
<pre><code>1. Traning/Validation/Test set 을 나눈다. 

2. Training set 에 모델 피팅을 한다. 

3. Validation/Test set 에 대해 예측을 한다. 

4. Validation set 과 Validation set 에 대한 예측이 새로운 모델을 만드는 데에 사용된다.

5. 4의 모델을 최종 Test set 에 대한 예측을 하는데 사용된다. 
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># train, test로 분리</span>
<span style="color:#75715e"># X : data , y : target</span>
x_train, x_test, y_train, y_test <span style="color:#f92672">=</span> train_test_split(X, y,
                                                    test_size <span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>,
                                                    stratify<span style="color:#f92672">=</span>y, <span style="color:#75715e"># target의 class 비율에 맞춰서 분리</span>
                                                    random_state <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span> )

<span style="color:#75715e"># Train set을 Train/Validation set로 분리</span>

x_train, x_val, y_train, y_val <span style="color:#f92672">=</span> train_test_split(X_train, y_train,
                                                  test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>, stratify<span style="color:#f92672">=</span>y_train,
                                                  random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">model1 <span style="color:#f92672">=</span> tree<span style="color:#f92672">.</span>DecisionTreeClassifier()
model1<span style="color:#f92672">.</span>fit(x_train, y_train)
val_pred1<span style="color:#f92672">=</span>model1<span style="color:#f92672">.</span>predict(x_val)
test_pred1<span style="color:#f92672">=</span>model1<span style="color:#f92672">.</span>predict(x_test)
val_pred1<span style="color:#f92672">=</span>pd<span style="color:#f92672">.</span>DataFrame(val_pred1)
test_pred1<span style="color:#f92672">=</span>pd<span style="color:#f92672">.</span>DataFrame(test_pred1)

model2 <span style="color:#f92672">=</span> KNeighborsClassifier()
model2<span style="color:#f92672">.</span>fit(x_train,y_train)
val_pred2<span style="color:#f92672">=</span>model2<span style="color:#f92672">.</span>predict(x_val)
test_pred2<span style="color:#f92672">=</span>model2<span style="color:#f92672">.</span>predict(x_test)
val_pred2<span style="color:#f92672">=</span>pd<span style="color:#f92672">.</span>DataFrame(val_pred2)
test_pred2<span style="color:#f92672">=</span>pd<span style="color:#f92672">.</span>DataFrame(test_pred2

</code></pre></div><p>아래 코드는 validation set 의 예측 결과 (Decision tree, KNN) 을 원래 feature 에 붙여서 새로운 데이터셋 df_val 을 만든 후, Final prediction model (이 예제에서는 Logistic regression model) 을 적합시키고, test set 에 대한 예측을 수행하는 것입니다.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">df_val<span style="color:#f92672">=</span>pd<span style="color:#f92672">.</span>concat([x_val, val_pred1,val_pred2],axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
df_test<span style="color:#f92672">=</span>pd<span style="color:#f92672">.</span>concat([x_test, test_pred1,test_pred2],axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)

model <span style="color:#f92672">=</span> LogisticRegression()
model<span style="color:#f92672">.</span>fit(df_val,y_val)
model<span style="color:#f92672">.</span>score(df_test,y_test)

</code></pre></div><h2 id="blending-과-stacking-의-차이점">Blending 과 Stacking 의 차이점</h2>
<pre><code>Blending 은 종종 다른 Ensemble technique 인 Stacking 과 비교가 됩니다.
Stacking 은 다른 예측 모형들의 결과값을 통해 새로운 모델을 만드는 Ensemble 방법입니다.
Stacking 의 경우는 Training set 의 예측값을 Training data 로 하여 Meta classifier (또는 Meta regression) 을 학습합니다.
그리고 이 Meta classifier 를 통해 Test set 을 예측합니다.
Blending 과 Stacking 의 차이점은 1) Blending 은 validation set 에 대한 예측값을 training 에 이용하지만, Stacking 은 training set 에 대한 예측값을 활용합니다.
2) Blending 을 예측값 뿐 아니라 원래 Feature 도 활용하는 반면, Stacking 은 예측값만 활용합니다. 그러면 이러한 의문이 남습니다. 
왜 validation set 만 활용해서 Final prediction model 을 구축해야하는가?
Training Set 에의 feature에 Training set 으로부터 예측한 예측값을 붙여서 활용하면 되지 않는가? 입니다.
만약 training performance 와 validation performance 가 비슷하다면 가능한 방법입니다. 하지만 training performance 가 높다면, feature 가 예측에 별로 필요하지 않게 됩니다.
따라서 feature를 예측에 활용하는 blending 의 장점이 없게 됩니다.
따라서 blending 을 잘활용하기 위해서는 validation set 의 meta-feature (원래 feature 및 예측값) 을 통해 training 하고, test set 에 대해 성능을 최종 평가해야합니다. 
</code></pre>
<p>출처 : <a href="https://3months.tistory.com/486">https://3months.tistory.com/486</a></p>

		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/machine_learning/" rel="tag">machine_learning</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>

<div class="authorbox clearfix">
	<div class="authorbox__header">
		<span class="authorbox__name">About JiHun</span>
	</div>
	<div class="authorbox__description">
		John Doe&rsquo;s true identity is unknown. Maybe he is a successful blogger or writer. Nobody knows it.
	</div>
</div>

<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/post/machine-learning-11/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">pseudo labeling</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/post/machine-learning-13/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">베이지안 최적화 기법 이론 보충</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2021 JiHun.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>
<script src="/js/custom.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script>
</body>
</html>