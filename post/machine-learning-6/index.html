<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>GAN 이론 - My New Hugo Site</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="GAN 이론" />
<meta property="og:description" content="GAN이란? GAN은 &lsquo;생성적 적대 신경망&rsquo;의 약자로 풀어서 쓰면, 생성자와 식별자가 서로 경쟁(Adversarial)하며 데이터를 생성(Generative)하는 모델(Network)을 뜻한다.
잡음의 이미지로부터 무엇인가를 생성해낸 결과에 대해서 분류기라고 하는 Dis가 G(Z)를 가짜라고 분류함 반면에 원래의 이미지를 받아왔을 때 원래 이미지에 대해서는 Positive하게 반응함 원래 이미지에 대해서는 확률 높게 판단해주고 가짜 이미지에 대해서는 확신도를 아주 낮게 준다.   잡음 이미지 Z 생성신경망 통과 Generator 생성 이미지 획득 G(Z) 원 이미지 X 분류기 통과 Discriminator(원래 이미지와 생성기로부터 만들어진 이미지를 동시에 입력받음) 두 분류 결과 (1:생성이미지 D(G(Z)), 2:원래이미지 D(X)) 1번에 대해서는 가짜, 2번에 대해서는 진짜로 분류하게끔 학습 목표를 제공해주어야 하는 것이 알고리즘의 총흐름도 이전 6단계 결과에 대한 적대적 학습시행 -&gt; 생성이미지 출신 저하(생성이미지가 가짜다) &amp; 원래이미지 출신 상승(원래이미지에 대한 확률을 높게 평가한다)  Gradient descending 경사하강법을 이용하면 어떤 지점으로 수렴하게 되는 결과를 받아들임 이 함수의 곡선을 가지고 Gradient ascending을 한다고 가정하면 바깥 영역에서 함수들이 굉장히 커지게 되며 그 끝을 알 수 없기 때문에 학습이 엉망으로 진행된다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://sjh4773.github.io/post/machine-learning-6/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2021-04-04T23:25:57&#43;00:00" />
<meta property="article:modified_time" content="2021-04-04T23:25:57&#43;00:00" />


		<meta itemprop="name" content="GAN 이론">
<meta itemprop="description" content="GAN이란? GAN은 &lsquo;생성적 적대 신경망&rsquo;의 약자로 풀어서 쓰면, 생성자와 식별자가 서로 경쟁(Adversarial)하며 데이터를 생성(Generative)하는 모델(Network)을 뜻한다.
잡음의 이미지로부터 무엇인가를 생성해낸 결과에 대해서 분류기라고 하는 Dis가 G(Z)를 가짜라고 분류함 반면에 원래의 이미지를 받아왔을 때 원래 이미지에 대해서는 Positive하게 반응함 원래 이미지에 대해서는 확률 높게 판단해주고 가짜 이미지에 대해서는 확신도를 아주 낮게 준다.   잡음 이미지 Z 생성신경망 통과 Generator 생성 이미지 획득 G(Z) 원 이미지 X 분류기 통과 Discriminator(원래 이미지와 생성기로부터 만들어진 이미지를 동시에 입력받음) 두 분류 결과 (1:생성이미지 D(G(Z)), 2:원래이미지 D(X)) 1번에 대해서는 가짜, 2번에 대해서는 진짜로 분류하게끔 학습 목표를 제공해주어야 하는 것이 알고리즘의 총흐름도 이전 6단계 결과에 대한 적대적 학습시행 -&gt; 생성이미지 출신 저하(생성이미지가 가짜다) &amp; 원래이미지 출신 상승(원래이미지에 대한 확률을 높게 평가한다)  Gradient descending 경사하강법을 이용하면 어떤 지점으로 수렴하게 되는 결과를 받아들임 이 함수의 곡선을 가지고 Gradient ascending을 한다고 가정하면 바깥 영역에서 함수들이 굉장히 커지게 되며 그 끝을 알 수 없기 때문에 학습이 엉망으로 진행된다."><meta itemprop="datePublished" content="2021-04-04T23:25:57&#43;00:00" />
<meta itemprop="dateModified" content="2021-04-04T23:25:57&#43;00:00" />
<meta itemprop="wordCount" content="218">
<meta itemprop="keywords" content="machine_learning," />
		<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="GAN 이론"/>
<meta name="twitter:description" content="GAN이란? GAN은 &lsquo;생성적 적대 신경망&rsquo;의 약자로 풀어서 쓰면, 생성자와 식별자가 서로 경쟁(Adversarial)하며 데이터를 생성(Generative)하는 모델(Network)을 뜻한다.
잡음의 이미지로부터 무엇인가를 생성해낸 결과에 대해서 분류기라고 하는 Dis가 G(Z)를 가짜라고 분류함 반면에 원래의 이미지를 받아왔을 때 원래 이미지에 대해서는 Positive하게 반응함 원래 이미지에 대해서는 확률 높게 판단해주고 가짜 이미지에 대해서는 확신도를 아주 낮게 준다.   잡음 이미지 Z 생성신경망 통과 Generator 생성 이미지 획득 G(Z) 원 이미지 X 분류기 통과 Discriminator(원래 이미지와 생성기로부터 만들어진 이미지를 동시에 입력받음) 두 분류 결과 (1:생성이미지 D(G(Z)), 2:원래이미지 D(X)) 1번에 대해서는 가짜, 2번에 대해서는 진짜로 분류하게끔 학습 목표를 제공해주어야 하는 것이 알고리즘의 총흐름도 이전 6단계 결과에 대한 적대적 학습시행 -&gt; 생성이미지 출신 저하(생성이미지가 가짜다) &amp; 원래이미지 출신 상승(원래이미지에 대한 확률을 높게 평가한다)  Gradient descending 경사하강법을 이용하면 어떤 지점으로 수렴하게 되는 결과를 받아들임 이 함수의 곡선을 가지고 Gradient ascending을 한다고 가정하면 바깥 영역에서 함수들이 굉장히 커지게 되며 그 끝을 알 수 없기 때문에 학습이 엉망으로 진행된다."/>

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	<link rel="stylesheet" href="/css/custom.css">

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="My New Hugo Site" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">My New Hugo Site</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">GAN 이론</h1>
			<div class="post__meta meta"><div class="meta__item-author meta__item">
	<svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2 0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class="meta__text">JiHun</span>
</div>
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2021-04-04T23:25:57Z">2021-04-04</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/machine_learning/" rel="category">machine_learning</a>
	</span>
</div></div>
		</header>
<div class="post__toc toc">
	<div class="toc__title">Page content</div>
	<div class="toc__menu">
		<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#생성신경망을-어떻게-loss-함수를-적용해서-트레이닝-시킬-것인가">생성신경망을 어떻게 loss 함수를 적용해서 트레이닝 시킬 것인가?</a></li>
      </ul>
    </li>
  </ul>
</nav>
	</div>
</div><div class="content post__content clearfix">
			<h1 id="gan이란">GAN이란?</h1>
<p>GAN은 &lsquo;생성적 적대 신경망&rsquo;의 약자로 풀어서 쓰면, 생성자와 식별자가 서로 경쟁(Adversarial)하며 데이터를 생성(Generative)하는 모델(Network)을 뜻한다.</p>
<p><img src="/image/GAN3.PNG" alt=""></p>
<p><img src="/image/GAN5.PNG" alt=""></p>
<pre><code>잡음의 이미지로부터 무엇인가를 생성해낸 결과에 대해서 분류기라고 하는 Dis가 G(Z)를 가짜라고
분류함 반면에 원래의 이미지를 받아왔을 때 원래 이미지에 대해서는 Positive하게 반응함
원래 이미지에 대해서는 확률 높게 판단해주고 가짜 이미지에 대해서는 확신도를 아주 낮게 준다.
</code></pre>
<ol>
<li>잡음 이미지 Z</li>
<li>생성신경망 통과 Generator</li>
<li>생성 이미지 획득 G(Z)</li>
<li>원 이미지 X</li>
<li>분류기 통과 Discriminator(원래 이미지와 생성기로부터 만들어진 이미지를 동시에 입력받음)</li>
<li>두 분류 결과 (1:생성이미지 D(G(Z)), 2:원래이미지 D(X))
1번에 대해서는 가짜, 2번에 대해서는 진짜로 분류하게끔 학습 목표를 제공해주어야 하는 것이 알고리즘의 총흐름도</li>
<li>이전 6단계 결과에 대한 적대적 학습시행
<img src="/image/GAN1.PNG" alt="">
-&gt; 생성이미지 출신 저하(생성이미지가 가짜다) &amp; 원래이미지 출신 상승(원래이미지에 대한 확률을 높게 평가한다)</li>
</ol>
<p><img src="/image/GAN4.PNG" alt=""></p>
<p>Gradient descending
경사하강법을 이용하면 어떤 지점으로 수렴하게 되는 결과를 받아들임
이 함수의 곡선을 가지고 Gradient ascending을 한다고 가정하면 바깥 영역에서 함수들이 굉장히 커지게 되며
그 끝을 알 수 없기 때문에 학습이 엉망으로 진행된다.</p>
<p>Gradient ascending
Gradient ascending을 사용하려면 함수가 기본적으로 위로 볼록한 형태가 되어야한다.
함수의 최고점(가장 볼록한 부분)에서 Discriminator가 진짜를 진짜로 분류하고 가짜를 가짜로 분류하게 된다.</p>
<p><img src="/image/GAN2.PNG" alt=""></p>
<h3 id="생성신경망을-어떻게-loss-함수를-적용해서-트레이닝-시킬-것인가">생성신경망을 어떻게 loss 함수를 적용해서 트레이닝 시킬 것인가?</h3>
<p>generator 부분에서는 식이 +이다 이것을 보았을 때 Discriminator와 generator가 적대적으로 학습한다는 것을 알 수 있다.
generator가 잘학습하게 되면 log(1-D(G(Z)))라고 하는 부분이 줄어들게 된다.</p>
<p>Discriminator의 목적은 진짜를 진짜로 가짜를 가짜로 인식하게끔 하는게 목표
generator은 가짜를 진짜로 진짜를 가짜로 표현하게끔 표현하는 것이 목표</p>

		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/machine_learning/" rel="tag">machine_learning</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>

<div class="authorbox clearfix">
	<div class="authorbox__header">
		<span class="authorbox__name">About JiHun</span>
	</div>
	<div class="authorbox__description">
		John Doe&rsquo;s true identity is unknown. Maybe he is a successful blogger or writer. Nobody knows it.
	</div>
</div>

<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/post/machine-learning-5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">데이터 전처리</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/post/sklearn-1/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">StandardScaler()</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2021 JiHun.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>
<script src="/js/custom.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script>
</body>
</html>