<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>rnn in pytorch - My New Hugo Site</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="rnn in pytorch" />
<meta property="og:description" content="RNN in PyTorch 파이토치에서는 nn.RNN()을 통해서 RNN 셀을 구현
import torch import torch.nn as nn 입력의 크기와 은닉 상태의 크기를 정의 input_size = 5 # 입력의 크기 hidden_size = 8 # 은닉 상태의 크기 입력 텐서를 정의한다. 입력 텐서는 (배치 크기 x 시점의 수 x 매 시점마다 들어가는 입력)의 크기를 가진다. 배치의 크기는 1이며 10번의 시점동안 5차원의 입력 벡터가 들어가도록 텐서를 정의한다. # (batch_size, time_steps, input_size) inputs = torch.Tensor(1, 10, 5) nn." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://sjh4773.github.io/post/rnn/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2021-06-01T22:48:42&#43;09:00" />
<meta property="article:modified_time" content="2021-06-01T22:48:42&#43;09:00" />


		<meta itemprop="name" content="rnn in pytorch">
<meta itemprop="description" content="RNN in PyTorch 파이토치에서는 nn.RNN()을 통해서 RNN 셀을 구현
import torch import torch.nn as nn 입력의 크기와 은닉 상태의 크기를 정의 input_size = 5 # 입력의 크기 hidden_size = 8 # 은닉 상태의 크기 입력 텐서를 정의한다. 입력 텐서는 (배치 크기 x 시점의 수 x 매 시점마다 들어가는 입력)의 크기를 가진다. 배치의 크기는 1이며 10번의 시점동안 5차원의 입력 벡터가 들어가도록 텐서를 정의한다. # (batch_size, time_steps, input_size) inputs = torch.Tensor(1, 10, 5) nn."><meta itemprop="datePublished" content="2021-06-01T22:48:42&#43;09:00" />
<meta itemprop="dateModified" content="2021-06-01T22:48:42&#43;09:00" />
<meta itemprop="wordCount" content="552">
<meta itemprop="keywords" content="Deep_learning," />
		<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="rnn in pytorch"/>
<meta name="twitter:description" content="RNN in PyTorch 파이토치에서는 nn.RNN()을 통해서 RNN 셀을 구현
import torch import torch.nn as nn 입력의 크기와 은닉 상태의 크기를 정의 input_size = 5 # 입력의 크기 hidden_size = 8 # 은닉 상태의 크기 입력 텐서를 정의한다. 입력 텐서는 (배치 크기 x 시점의 수 x 매 시점마다 들어가는 입력)의 크기를 가진다. 배치의 크기는 1이며 10번의 시점동안 5차원의 입력 벡터가 들어가도록 텐서를 정의한다. # (batch_size, time_steps, input_size) inputs = torch.Tensor(1, 10, 5) nn."/>

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	<link rel="stylesheet" href="/css/custom.css">

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="My New Hugo Site" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">My New Hugo Site</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">rnn in pytorch</h1>
			<div class="post__meta meta"><div class="meta__item-author meta__item">
	<svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2 0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class="meta__text">JiHun</span>
</div>
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2021-06-01T22:48:42&#43;09:00">2021-06-01</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/deep_learning/" rel="category">Deep_learning</a>
	</span>
</div></div>
		</header>
<div class="post__toc toc">
	<div class="toc__title">Page content</div>
	<div class="toc__menu">
		<nav id="TableOfContents">
  <ul>
    <li><a href="#simple-example">Simple Example</a></li>
    <li><a href="#timeseries">timeseries</a></li>
  </ul>
</nav>
	</div>
</div><div class="content post__content clearfix">
			<h1 id="rnn-in-pytorch">RNN in PyTorch</h1>
<p>파이토치에서는 nn.RNN()을 통해서 RNN 셀을 구현</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">

<span style="color:#f92672">import</span> torch
<span style="color:#f92672">import</span> torch.nn <span style="color:#f92672">as</span> nn
<span style="color:#960050;background-color:#1e0010">입력의</span> <span style="color:#960050;background-color:#1e0010">크기와</span> <span style="color:#960050;background-color:#1e0010">은닉</span> <span style="color:#960050;background-color:#1e0010">상태의</span> <span style="color:#960050;background-color:#1e0010">크기를</span> <span style="color:#960050;background-color:#1e0010">정의</span>


input_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span> <span style="color:#75715e"># 입력의 크기</span>
hidden_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">8</span> <span style="color:#75715e"># 은닉 상태의 크기</span>
<span style="color:#960050;background-color:#1e0010">입력</span> <span style="color:#960050;background-color:#1e0010">텐서를</span> <span style="color:#960050;background-color:#1e0010">정의한다</span><span style="color:#f92672">.</span> <span style="color:#960050;background-color:#1e0010">입력</span> <span style="color:#960050;background-color:#1e0010">텐서는</span> (<span style="color:#960050;background-color:#1e0010">배치</span> <span style="color:#960050;background-color:#1e0010">크기</span> x <span style="color:#960050;background-color:#1e0010">시점의</span> <span style="color:#960050;background-color:#1e0010">수</span> x <span style="color:#960050;background-color:#1e0010">매</span> <span style="color:#960050;background-color:#1e0010">시점마다</span> <span style="color:#960050;background-color:#1e0010">들어가는</span> <span style="color:#960050;background-color:#1e0010">입력</span>)<span style="color:#960050;background-color:#1e0010">의</span> <span style="color:#960050;background-color:#1e0010">크기를</span> <span style="color:#960050;background-color:#1e0010">가진다</span><span style="color:#f92672">.</span>

<span style="color:#960050;background-color:#1e0010">배치의</span> <span style="color:#960050;background-color:#1e0010">크기는</span> <span style="color:#ae81ff">1</span><span style="color:#960050;background-color:#1e0010">이며</span> <span style="color:#ae81ff">10</span><span style="color:#960050;background-color:#1e0010">번의</span> <span style="color:#960050;background-color:#1e0010">시점동안</span> <span style="color:#ae81ff">5</span><span style="color:#960050;background-color:#1e0010">차원의</span> <span style="color:#960050;background-color:#1e0010">입력</span> <span style="color:#960050;background-color:#1e0010">벡터가</span> <span style="color:#960050;background-color:#1e0010">들어가도록</span> <span style="color:#960050;background-color:#1e0010">텐서를</span> <span style="color:#960050;background-color:#1e0010">정의한다</span><span style="color:#f92672">.</span>


<span style="color:#75715e"># (batch_size, time_steps, input_size)</span>
inputs <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>Tensor(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">5</span>)
nn<span style="color:#f92672">.</span>RNN()<span style="color:#960050;background-color:#1e0010">을</span> <span style="color:#960050;background-color:#1e0010">사용하여</span> RNN의 <span style="color:#960050;background-color:#1e0010">셀을</span> <span style="color:#960050;background-color:#1e0010">만든다</span><span style="color:#f92672">.</span> <span style="color:#960050;background-color:#1e0010">인자로</span> <span style="color:#960050;background-color:#1e0010">입력의</span> <span style="color:#960050;background-color:#1e0010">크기</span>, <span style="color:#960050;background-color:#1e0010">은닉</span> <span style="color:#960050;background-color:#1e0010">상태의</span> <span style="color:#960050;background-color:#1e0010">크기를</span> <span style="color:#960050;background-color:#1e0010">정의해주고</span>, batch_first<span style="color:#f92672">=</span>True를 <span style="color:#960050;background-color:#1e0010">통해서</span> <span style="color:#960050;background-color:#1e0010">입력</span> <span style="color:#960050;background-color:#1e0010">텐서의</span> <span style="color:#960050;background-color:#1e0010">첫번째</span> <span style="color:#960050;background-color:#1e0010">차원이</span> <span style="color:#960050;background-color:#1e0010">배치</span> <span style="color:#960050;background-color:#1e0010">크기임을</span> <span style="color:#960050;background-color:#1e0010">알려준다</span><span style="color:#f92672">.</span>


cell <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>RNN(input_size, hidden_size, batch_first<span style="color:#f92672">=</span>True)
<span style="color:#960050;background-color:#1e0010">입력</span> <span style="color:#960050;background-color:#1e0010">텐서를</span> RNN <span style="color:#960050;background-color:#1e0010">셀에</span> <span style="color:#960050;background-color:#1e0010">입력하여</span> <span style="color:#960050;background-color:#1e0010">출력을</span> <span style="color:#960050;background-color:#1e0010">확인</span>


outputs, _status <span style="color:#f92672">=</span> cell(inputs)
RNN <span style="color:#960050;background-color:#1e0010">셀은</span> <span style="color:#960050;background-color:#1e0010">두</span> <span style="color:#960050;background-color:#1e0010">개의</span> <span style="color:#960050;background-color:#1e0010">입력을</span> <span style="color:#960050;background-color:#1e0010">리턴하는데</span>, <span style="color:#960050;background-color:#1e0010">첫번째</span> <span style="color:#960050;background-color:#1e0010">리턴값은</span> <span style="color:#960050;background-color:#1e0010">모든</span> <span style="color:#960050;background-color:#1e0010">시점의</span> <span style="color:#960050;background-color:#1e0010">은닉</span> <span style="color:#960050;background-color:#1e0010">상태들이며</span>, <span style="color:#960050;background-color:#1e0010">두번째</span> <span style="color:#960050;background-color:#1e0010">리턴값은</span> <span style="color:#960050;background-color:#1e0010">마지막</span> <span style="color:#960050;background-color:#1e0010">시점의</span> <span style="color:#960050;background-color:#1e0010">은닉</span> <span style="color:#960050;background-color:#1e0010">상태이다</span><span style="color:#f92672">.</span>

<span style="color:#960050;background-color:#1e0010">첫번째</span> <span style="color:#960050;background-color:#1e0010">리턴값에</span> <span style="color:#960050;background-color:#1e0010">대해서</span> <span style="color:#960050;background-color:#1e0010">크기</span> <span style="color:#960050;background-color:#1e0010">확인</span><span style="color:#f92672">.</span>


<span style="color:#66d9ef">print</span>(outputs<span style="color:#f92672">.</span>shape) <span style="color:#75715e"># 모든 time-step의 hidden_state</span>
<span style="color:#960050;background-color:#1e0010">첫번째</span> <span style="color:#960050;background-color:#1e0010">리턴값의</span> <span style="color:#960050;background-color:#1e0010">은닉</span> <span style="color:#960050;background-color:#1e0010">상태들은</span> (<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">8</span>)<span style="color:#960050;background-color:#1e0010">의</span> <span style="color:#960050;background-color:#1e0010">크기를</span> <span style="color:#960050;background-color:#1e0010">가진다</span><span style="color:#f92672">.</span> <span style="color:#960050;background-color:#1e0010">이는</span> <span style="color:#ae81ff">10</span><span style="color:#960050;background-color:#1e0010">번의</span> <span style="color:#960050;background-color:#1e0010">시점동안</span> <span style="color:#ae81ff">8</span><span style="color:#960050;background-color:#1e0010">차원의</span> <span style="color:#960050;background-color:#1e0010">은닉상태가</span> <span style="color:#960050;background-color:#1e0010">출력되었다는</span> <span style="color:#960050;background-color:#1e0010">의미이다</span><span style="color:#f92672">.</span>

<span style="color:#960050;background-color:#1e0010">두</span> <span style="color:#960050;background-color:#1e0010">번째</span> <span style="color:#960050;background-color:#1e0010">리턴값</span><span style="color:#f92672">.</span> <span style="color:#960050;background-color:#1e0010">다시</span> <span style="color:#960050;background-color:#1e0010">말해</span> <span style="color:#960050;background-color:#1e0010">마지막</span> <span style="color:#960050;background-color:#1e0010">시점의</span> <span style="color:#960050;background-color:#1e0010">은닉</span> <span style="color:#960050;background-color:#1e0010">상태의</span> <span style="color:#960050;background-color:#1e0010">크기를</span> <span style="color:#960050;background-color:#1e0010">확인</span><span style="color:#f92672">.</span>


<span style="color:#66d9ef">print</span>(_status<span style="color:#f92672">.</span>shape) <span style="color:#75715e"># 최종 time-step의 hidden_state</span>
</code></pre></div><h2 id="simple-example">Simple Example</h2>
<p>예시 : Hell가 들어가면 다음 알파벳 o를 맞추기</p>
<p><img src="/image/rnn1.PNG" alt=""></p>
<pre><code>input_size : 4 (h의 차원의 크기 : [1, 0, 0, 0] )
hidden_size : 2 (특별한 이유는 없지만, 슬픔, 기쁨, 분노 중 하나를 추론한다면 3으로 둘 수 있음)
hidden_size의 크기가 outputs의 마지막 shape가 됨
이유는 아래의 첨부한 사진과 같음. hidden_state의 출력이 하나는 output으로 하고 다른 하나는 다음번 hidden_state로 가기에 둘은 같은 값을 가지게 됨
</code></pre>
<p><img src="/image/rnn2.PNG" alt=""></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">
sequence length : <span style="color:#ae81ff">0</span><span style="color:#960050;background-color:#1e0010">부터</span> t까지의 <span style="color:#960050;background-color:#1e0010">길이를</span> <span style="color:#960050;background-color:#1e0010">가지는</span> <span style="color:#960050;background-color:#1e0010">입력값</span>
<span style="color:#960050;background-color:#1e0010">예</span>) h, e, l, l, o의 <span style="color:#960050;background-color:#1e0010">경우</span> sequence length는 <span style="color:#ae81ff">5</span> output의 <span style="color:#960050;background-color:#1e0010">중간</span> shape가 sequence length가 <span style="color:#960050;background-color:#1e0010">됨</span>(<span style="color:#960050;background-color:#1e0010">이건</span> <span style="color:#960050;background-color:#1e0010">모델이</span> <span style="color:#960050;background-color:#1e0010">알아서</span> <span style="color:#960050;background-color:#1e0010">인식함</span>)
</code></pre></div><p><img src="/image/rnn3.PNG" alt=""></p>
<p>batch size 역시 모델에 입력할 필요가 없이 input data만 잘 구성하면 알아서 인식됨</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">

<span style="color:#f92672">import</span> torch
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np

<span style="color:#75715e"># Random seed to make results deterministic and reproducible</span>
torch<span style="color:#f92672">.</span>manual_seed(<span style="color:#ae81ff">0</span>)

<span style="color:#75715e"># declare dimension</span>
input_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">4</span>
hidden_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>
</code></pre></div><h2 id="timeseries">timeseries</h2>
<p><img src="/image/rnn4.PNG" alt=""></p>
<pre><code>이 데이터를 넣는 모델을 보면 기본적으로 7일간의 데이터를 입력 받아서 8일차 종가를 예측하는 구조로 되어있다.

이 모델은 8일차의 종가를 예측하기 위해서 그전 일주일간의 데이터를 보면 될것이라는 전제로부터 출발한다. 그러나 주식시장에는 여러가지의 가정이 있기 때문에 옳지 않은 전제라고 볼 수 있으며 단지 이러한 전제로 출발했다는 사실을 알린다.
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">
<span style="color:#f92672">import</span> torch
<span style="color:#f92672">import</span> torch.optim <span style="color:#f92672">as</span> optim
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt

<span style="color:#75715e"># Random seed to make result deterministi and reproducible</span>
torch<span style="color:#f92672">.</span>manual_seed(<span style="color:#ae81ff">0</span>)

<span style="color:#75715e"># scaling function for input data</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">minmax_scaler</span>(data):
    numerator <span style="color:#f92672">=</span> data <span style="color:#f92672">-</span> np<span style="color:#f92672">.</span>min(data, <span style="color:#ae81ff">0</span>)
    denominator <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>max(data, <span style="color:#ae81ff">0</span>) <span style="color:#f92672">-</span> np<span style="color:#f92672">.</span>min(data, <span style="color:#ae81ff">0</span>)
    <span style="color:#66d9ef">return</span> numerator <span style="color:#f92672">/</span> (denominator <span style="color:#f92672">+</span> <span style="color:#ae81ff">1e-7</span>)

<span style="color:#75715e"># make dataset to input</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_dataset</span>(time_series, seq_length):
    dataX <span style="color:#f92672">=</span> []
    dataY <span style="color:#f92672">=</span> []
    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">0</span>, len(time_series) <span style="color:#f92672">-</span> seq_length):
        _x <span style="color:#f92672">=</span> time_series[i:i <span style="color:#f92672">+</span> seq_length, :]
        _y <span style="color:#f92672">=</span> time_series[i <span style="color:#f92672">+</span> seq_length, [<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]] <span style="color:#75715e"># Next close price</span>
        <span style="color:#66d9ef">print</span>(_x, <span style="color:#e6db74">&#34;-&gt;&#34;</span>, _y)
        dataX<span style="color:#f92672">.</span>append(_x)
        dataY<span style="color:#f92672">.</span>append(_y)


<span style="color:#75715e"># hyper parameters</span>
seq_length <span style="color:#f92672">=</span> <span style="color:#ae81ff">7</span>   <span style="color:#75715e"># 7일</span>
data_dim <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span>     <span style="color:#75715e"># 시가,최고가,최저가,거래량,종가</span>
hidden_dim <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span>  
output_dim <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>   <span style="color:#75715e"># 마지막에 fully connected dimension이 맞춰야 하는 종가</span>
learning_rate <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.01</span>
iterations <span style="color:#f92672">=</span> <span style="color:#ae81ff">500</span>

<span style="color:#75715e"># 파이토치가 읽을 수 있는 텐서의 형태로 변환</span>
trainX_tensor <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>FloatTensor(trainX)
trainY_tensor <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>FloatTensor(trainY)

testX_tensor <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>FloatTensor(testX)
testY_tensor <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>FloatTensor(testY)

<span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Net</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module):
    <span style="color:#66d9ef">def</span> __init__(self, input_dim, hidden_dim, output_dim, layers):
        super(Net, self)<span style="color:#f92672">.</span>__init__()
        self<span style="color:#f92672">.</span>rnn <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>LSTM(input_dim, hidden_dim, num_layers<span style="color:#f92672">=</span>layers, batch_first<span style="color:#f92672">=</span>True)
        self<span style="color:#f92672">.</span>fc <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Linear(hidden_dim, output_dim, bias<span style="color:#f92672">=</span>True) <span style="color:#75715e"># fully connected layer 선언</span>

    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
        x, _status <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>rnn(x)
        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>fc(x[:,<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>])
        <span style="color:#66d9ef">return</span> x


<span style="color:#75715e"># start training</span>
<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(iterations):

    optimizer<span style="color:#f92672">.</span>zero_grad()
    outputs <span style="color:#f92672">=</span> net(trainX_tensor)
    loss <span style="color:#f92672">=</span> criterion(outputs, trainY_tensor)
    loss<span style="color:#f92672">.</span>backward()
    optimizer<span style="color:#f92672">.</span>step()
    <span style="color:#66d9ef">print</span>(i, loss<span style="color:#f92672">.</span>item())

plt<span style="color:#f92672">.</span>plot(testY)
plt<span style="color:#f92672">.</span>plot(net(testX_tensor)<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>numpy())
plt<span style="color:#f92672">.</span>legend([<span style="color:#e6db74">&#39;original&#39;</span>, <span style="color:#e6db74">&#39;prediction&#39;</span>])
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p><img src="/image/rnn5.PNG" alt=""></p>

		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/deep_learning/" rel="tag">Deep_learning</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>

<div class="authorbox clearfix">
	<div class="authorbox__header">
		<span class="authorbox__name">About JiHun</span>
	</div>
	<div class="authorbox__description">
		John Doe&rsquo;s true identity is unknown. Maybe he is a successful blogger or writer. Nobody knows it.
	</div>
</div>

<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/post/meta/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">메타러닝</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/post/seq2seq/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Seq2seq with attention</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2021 JiHun.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>
<script src="/js/custom.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script>
</body>
</html>