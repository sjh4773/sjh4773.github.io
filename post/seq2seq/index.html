<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Seq2seq with attention - My New Hugo Site</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Seq2seq with attention" />
<meta property="og:description" content="인코더의 주 역할은 각 단어를 순차적으로 받음으로써 최종적으로 문맥 벡터를 만드는 것 디코더의 역할은 문맥 벡터로부터 기계번역을 시작 시퀀스가 적을 경우 문제가 없으나 시퀀스가 길어질경우 문제 발생 문맥 벡터는 고정된 사이즈의 벡터이므로 모든 정보를 함축하기에는 사이즈가 작다 그 대안으로 attention 메카니즘을 활용한다. 이전 인코더 디코더 아키텍처에서는 인코더에서 나왔던 모든 state를 활용하지 않았다 단순히 마지막에 나온 state를 context vector라고 불렀고 그 하나의 context vector에서 translation이 이루어졌다. encoder 나온 각각의 rnn의 셀의 state를 활용하여 decoder에서 dynamic하게 context vector를 만들어 번역을 한다면 고정된 사이즈의 문제를 해결할 수 있다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://sjh4773.github.io/post/seq2seq/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2021-06-03T00:09:15&#43;09:00" />
<meta property="article:modified_time" content="2021-06-03T00:09:15&#43;09:00" />


		<meta itemprop="name" content="Seq2seq with attention">
<meta itemprop="description" content="인코더의 주 역할은 각 단어를 순차적으로 받음으로써 최종적으로 문맥 벡터를 만드는 것 디코더의 역할은 문맥 벡터로부터 기계번역을 시작 시퀀스가 적을 경우 문제가 없으나 시퀀스가 길어질경우 문제 발생 문맥 벡터는 고정된 사이즈의 벡터이므로 모든 정보를 함축하기에는 사이즈가 작다 그 대안으로 attention 메카니즘을 활용한다. 이전 인코더 디코더 아키텍처에서는 인코더에서 나왔던 모든 state를 활용하지 않았다 단순히 마지막에 나온 state를 context vector라고 불렀고 그 하나의 context vector에서 translation이 이루어졌다. encoder 나온 각각의 rnn의 셀의 state를 활용하여 decoder에서 dynamic하게 context vector를 만들어 번역을 한다면 고정된 사이즈의 문제를 해결할 수 있다."><meta itemprop="datePublished" content="2021-06-03T00:09:15&#43;09:00" />
<meta itemprop="dateModified" content="2021-06-03T00:09:15&#43;09:00" />
<meta itemprop="wordCount" content="384">
<meta itemprop="keywords" content="Deep_learning," />
		<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Seq2seq with attention"/>
<meta name="twitter:description" content="인코더의 주 역할은 각 단어를 순차적으로 받음으로써 최종적으로 문맥 벡터를 만드는 것 디코더의 역할은 문맥 벡터로부터 기계번역을 시작 시퀀스가 적을 경우 문제가 없으나 시퀀스가 길어질경우 문제 발생 문맥 벡터는 고정된 사이즈의 벡터이므로 모든 정보를 함축하기에는 사이즈가 작다 그 대안으로 attention 메카니즘을 활용한다. 이전 인코더 디코더 아키텍처에서는 인코더에서 나왔던 모든 state를 활용하지 않았다 단순히 마지막에 나온 state를 context vector라고 불렀고 그 하나의 context vector에서 translation이 이루어졌다. encoder 나온 각각의 rnn의 셀의 state를 활용하여 decoder에서 dynamic하게 context vector를 만들어 번역을 한다면 고정된 사이즈의 문제를 해결할 수 있다."/>

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	<link rel="stylesheet" href="/css/custom.css">

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="My New Hugo Site" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">My New Hugo Site</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Seq2seq with attention</h1>
			<div class="post__meta meta"><div class="meta__item-author meta__item">
	<svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2 0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class="meta__text">JiHun</span>
</div>
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2021-06-03T00:09:15&#43;09:00">2021-06-03</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/deep_learning/" rel="category">Deep_learning</a>
	</span>
</div></div>
		</header><div class="content post__content clearfix">
			<pre><code>인코더의 주 역할은 각 단어를 순차적으로 받음으로써 최종적으로 문맥 벡터를 만드는 것
디코더의 역할은 문맥 벡터로부터 기계번역을 시작

시퀀스가 적을 경우 문제가 없으나 시퀀스가 길어질경우 문제 발생 
문맥 벡터는 고정된 사이즈의 벡터이므로 모든 정보를 함축하기에는 사이즈가 작다

그 대안으로 attention 메카니즘을 활용한다.

이전 인코더 디코더 아키텍처에서는 인코더에서 나왔던 모든 state를 활용하지 않았다
단순히 마지막에 나온 state를 context vector라고 불렀고 그 하나의 context vector에서 translation이 이루어졌다.

encoder 나온 각각의 rnn의 셀의 state를 활용하여 decoder에서 dynamic하게 context vector를
만들어 번역을 한다면 고정된 사이즈의 문제를 해결할 수 있다.

여기에서 얻는 장점 2가지
1. 고정된 사이즈의 문맥 벡터에서 발생한 문제를 각각의 state별로 context vector를 새로 만들어 해결
2. encoder에 있었던 모든 state 중에서 집중해야 할 단어들에게만 집중할 수 있는 메커니즘 설계 가능
</code></pre>
<p><img src="/image/seq1.PNG" alt=""></p>
<pre><code>여기에서 h3는 전통적인 seq2seq에서는 context vector였다.

seq2seq with attention
</code></pre>
<p><img src="/image/seq2.PNG" alt=""></p>
<pre><code>이번 방법을 보면 fully connected network가 있다.
보는 것처럼 h1,h2,h3 인코더 파트에서 나왔던 모든 rnn셀의 state를 활용하는 것을 볼 수 있음
그리고 최종에 나왔던 h3를 다시 넣었다. 지금 현재로써는 decoder에서 나온 값이 하나도 없기 때문에 단순히 전에 있었던 state 값을 넣어준 것이다.
</code></pre>
<p><img src="/image/seq3.PNG" alt=""></p>
<pre><code>Fully connect network를 통해 나온 값은 score1, score2, score3이다 즉 각 인코더에 있던 rnn의 state score값이다
여기에 softmax를 취해주면 확률값이 나온다.
이것을 attention weight라고 부르고 이 값들은 얼마만큼 우리가 focus 할 것인지를 결정
</code></pre>
<p><img src="/image/seq4.PNG" alt=""></p>
<pre><code>이렇게 첫번째 context vector를 만든다. 이것을 decoder 파트에 있는 첫번째 rnn 셀로 넣어주게 되고
지금까지 번역한 것이 없기 때문에 start라는 시그널을 넣어주게 된다.

First step으로 output이 나오게 되고
</code></pre>
<p><img src="/image/seq5.PNG" alt=""></p>
<p><img src="/image/seq6.PNG" alt=""></p>
<pre><code>Second step으로 현재에 있는 decode의 state 값이 fully connected network에 들어가게 되고
여기에서 중요한 것은 h1,h2,h3가 항상 쓰인다는 것이다. 즉 인코더에 있는 rnn 셀들의 state값들이 항상 쓰인다는 것이다.
왜냐하면 이 값들 중에서 어떤 값에 우리가 주요하게 포커스를 할것인할 것 대해 계산을 해야하기 때문이다.
위의 그림을 보면 first step의 context vector와 다른 값인 것을 알 수 있다. 즉 단순히 한 개의 context vector만 사용한 과거의 seq2seq 모델보다 다이나믹하게 context vector를 만드는
seq2seq + attention 메커니즘이 방대한 양의 information을 함축하는데 있어서 더 효율적이다.
Context vector가 decoder의 두번째 rnn 셀에 들어가게 되고 이전 셀에 나왔던 output 값이 또 input으로 들어오게 된다.
</code></pre>
<p><img src="/image/seq7.PNG" alt=""></p>
<pre><code>같은 방식으로 이번에는 dh2가 fully connected layer에 들어갔고 다시 한번 h1,h2,h3가 들어갔다.
이것들은 항상 필수로 들어가는데 왜냐하면 이  세 개 중에서 어떤 값에 더 집중할 것인지에 대해 관심이 있기 때문이다.
</code></pre>
<p><img src="/image/seq8.PNG" alt=""></p>
<pre><code>End가 나올때까지 반복
중요한 것은 attention weight ,인코더에 나온 state에서 어디를 focus 해서 볼 것인지에 대한 것이다.
Context vector가 각각 state 별로 decoding 할 때마다 달라진다.
</code></pre>
<p><img src="/image/seq9.PNG" alt=""></p>

		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/deep_learning/" rel="tag">Deep_learning</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>

<div class="authorbox clearfix">
	<div class="authorbox__header">
		<span class="authorbox__name">About JiHun</span>
	</div>
	<div class="authorbox__description">
		John Doe&rsquo;s true identity is unknown. Maybe he is a successful blogger or writer. Nobody knows it.
	</div>
</div>

<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/post/rnn/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">rnn in pytorch</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/post/transfomer/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Transfomer</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2021 JiHun.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>
<script src="/js/custom.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script>
</body>
</html>